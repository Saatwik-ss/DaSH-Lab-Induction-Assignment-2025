{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCfB3P9qhzoN",
        "outputId": "61007f21-ac2f-4ed5-d3b4-48024736aa41"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Nov 12 11:59:26 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3N4khlOOhHX5",
        "outputId": "3666e4e9-1291-47bf-f747-6208a9e326da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2024 NVIDIA Corporation\n",
            "Built on Thu_Jun__6_02:18:23_PDT_2024\n",
            "Cuda compilation tools, release 12.5, V12.5.82\n",
            "Build cuda_12.5.r12.5/compiler.34385749_0\n"
          ]
        }
      ],
      "source": [
        "!nvcc --version\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile matrix_mul_naive.cu\n",
        "#include <iostream>\n",
        "#include <cuda_runtime.h>\n",
        "#define N 1024\n",
        "\n",
        "\n",
        "__global__ void matrixMulNaive(const float* A, const float* B, float* C, int n) {\n",
        "    int row=blockIdx.y*blockDim.y +threadIdx.y;\n",
        "    int col=blockIdx.x*blockDim.x +threadIdx.x;\n",
        "    if (row <n && col<n) {\n",
        "        float val=0.0f;\n",
        "        for (int k=0; k< n; ++k)\n",
        "            val += A[row*n + k]*B[k * n + col];\n",
        "        C[row*n + col] = val;\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "int main() {\n",
        "    int size = N * N * sizeof(float);\n",
        "    float *h_A = (float*)malloc(size);\n",
        "    float *h_B = (float*)malloc(size);\n",
        "    float *h_C = (float*)malloc(size);\n",
        "    for (int i = 0; i < N * N; i++) {\n",
        "        h_A[i] = static_cast<float>(rand()) / RAND_MAX;\n",
        "        h_B[i] = static_cast<float>(rand()) / RAND_MAX;\n",
        "    }\n",
        "\n",
        "    float *d_A, *d_B, *d_C;\n",
        "    cudaMalloc(&d_A, size);\n",
        "    cudaMalloc(&d_B, size);\n",
        "    cudaMalloc(&d_C, size);\n",
        "    cudaMemcpy(d_A, h_A, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_B, h_B, size, cudaMemcpyHostToDevice);\n",
        "    dim3 threads(16, 16);\n",
        "    dim3 blocks((N + threads.x - 1) / threads.x, (N + threads.y - 1) / threads.y);\n",
        "\n",
        "    cudaEvent_t start, stop;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "\n",
        "    // run kernel\n",
        "    cudaEventRecord(start);\n",
        "    matrixMulNaive<<<blocks, threads>>>(d_A, d_B, d_C, N);\n",
        "    cudaEventRecord(stop);\n",
        "    cudaEventSynchronize(stop);\n",
        "\n",
        "    float ms = 0.0f;\n",
        "    cudaEventElapsedTime(&ms, start, stop);\n",
        "    cudaMemcpy(h_C, d_C, size, cudaMemcpyDeviceToHost);\n",
        "    double flops = 2.0 * N * N * N;\n",
        "    double gflops = flops / (ms * 1e6);\n",
        "    std::cout << \"Native CUDA Matrix Multiplication:\\n\";\n",
        "    std::cout << ms << \" ms,  Performance: \" << gflops << \" GFLOPS\\n\";\n",
        "\n",
        "    cudaFree(d_A);\n",
        "    cudaFree(d_B);\n",
        "    cudaFree(d_C);\n",
        "    free(h_A);\n",
        "    free(h_B);\n",
        "    free(h_C);\n",
        "    return 0;\n",
        "}\n",
        "\n",
        "// ###### COMPILE ###########\n",
        "//!nvcc -O3 -arch=sm_75 matrix_mul_naive.cu -o matrix_mul_naive\n",
        "//!./matrix_mul_naive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OD9TkqHbh8o-",
        "outputId": "d4214122-498c-4795-c37d-f86bca73aae7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting matrix_mul_naive.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -O3 -arch=sm_75 matrix_mul_naive.cu -o matrix_mul_naive\n",
        "!./matrix_mul_naive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hyXok6RX99I9",
        "outputId": "fb59a6b1-7f08-4520-cb0f-8e582ffdc6f3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Native CUDA Matrix Multiplication:\n",
            "9.23488 ms,  Performance: 232.54 GFLOPS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile matrix_mul_tiled_prof.cu\n",
        "#include <stdio.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "#define TILE 16\n",
        "\n",
        "__global__ void matmul_naive(const float *A,const float *B,float *C,int M,int N,int K){\n",
        " int row=blockIdx.y*blockDim.y+threadIdx.y;\n",
        " int col=blockIdx.x*blockDim.x+threadIdx.x;\n",
        " if(row<M && col<K){\n",
        "   float val=0;\n",
        "   for(int i=0;i<N;i++)\n",
        "     val+=A[row*N+i]*B[i*K+col];\n",
        "   C[row*K+col]=val;\n",
        " }\n",
        "}\n",
        "\n",
        "__global__ void matmul_tiled(const float *A,const float *B,float *C,int M,int N,int K){\n",
        " __shared__ float As[TILE][TILE];\n",
        " __shared__ float Bs[TILE][TILE];\n",
        " int row=blockIdx.y*TILE+threadIdx.y;\n",
        " int col=blockIdx.x*TILE+threadIdx.x;\n",
        " float val=0.0f;\n",
        " for(int t=0;t<(N+TILE-1)/TILE;t++){\n",
        "   if(row<M && t*TILE+threadIdx.x<N)\n",
        "     As[threadIdx.y][threadIdx.x]=A[row*N+t*TILE+threadIdx.x];\n",
        "   else As[threadIdx.y][threadIdx.x]=0.0f;\n",
        "\n",
        "   if(col<K && t*TILE+threadIdx.y<N)\n",
        "     Bs[threadIdx.y][threadIdx.x]=B[(t*TILE+threadIdx.y)*K+col];\n",
        "   else Bs[threadIdx.y][threadIdx.x]=0.0f;\n",
        "   __syncthreads();\n",
        "\n",
        "   for(int i=0;i<TILE;i++)\n",
        "     val+=As[threadIdx.y][i]*Bs[i][threadIdx.x];\n",
        "   __syncthreads();\n",
        " }\n",
        " if(row<M && col<K) C[row*K+col]=val;\n",
        "}\n",
        "\n",
        "void fill(float *a,int m,int n){\n",
        "  for(int i=0;i<m*n;i++) a[i]=(float)(rand()%10);\n",
        "}\n",
        "\n",
        "int main(){\n",
        " int M=1024,N=1024,K=1024;\n",
        " size_t sA=M*N*sizeof(float), sB=N*K*sizeof(float), sC=M*K*sizeof(float);\n",
        " float *hA=(float*)malloc(sA);\n",
        " float *hB=(float*)malloc(sB);\n",
        " float *hC=(float*)malloc(sC);\n",
        " fill(hA,M,N); fill(hB,N,K);\n",
        " float *dA,*dB,*dC;\n",
        " cudaMalloc(&dA,sA); cudaMalloc(&dB,sB); cudaMalloc(&dC,sC);\n",
        " cudaMemcpy(dA,hA,sA,cudaMemcpyHostToDevice);\n",
        " cudaMemcpy(dB,hB,sB,cudaMemcpyHostToDevice);\n",
        " dim3 block(TILE,TILE);\n",
        " dim3 grid((K+TILE-1)/TILE,(M+TILE-1)/TILE);\n",
        "\n",
        " cudaEvent_t start,stop;\n",
        " cudaEventCreate(&start); cudaEventCreate(&stop);\n",
        "\n",
        " cudaEventRecord(start);\n",
        " matmul_naive<<<grid,block>>>(dA,dB,dC,M,N,K);\n",
        " cudaEventRecord(stop);\n",
        " cudaEventSynchronize(stop);\n",
        " float ms1;\n",
        " cudaEventElapsedTime(&ms1,start,stop);\n",
        " double gflops1=2.0*M*N*K/(ms1/1000.0)/1e9;\n",
        " printf(\"Naive: %.4f ms  %.2f GFLOPS\\n\",ms1,gflops1);\n",
        "\n",
        " cudaMemset(dC,0,sC);\n",
        " cudaEventRecord(start);\n",
        " matmul_tiled<<<grid,block>>>(dA,dB,dC,M,N,K);\n",
        " cudaEventRecord(stop);\n",
        " cudaEventSynchronize(stop);\n",
        " float ms2;\n",
        " cudaEventElapsedTime(&ms2,start,stop);\n",
        " double gflops2=2.0*M*N*K/(ms2/1000.0)/1e9;\n",
        " printf(\"Tiled: %.4f ms  %.2f GFLOPS\\n\",ms2,gflops2);\n",
        "\n",
        " cudaFree(dA); cudaFree(dB); cudaFree(dC);\n",
        " free(hA); free(hB); free(hC);\n",
        " return 0;\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "//!nvcc -O3 -arch=sm_75 matrix_mul_tiled_prof.cu -o matrix_mul_tiled_prof\n",
        "//!nvprof ./matrix_mul_tiled_prof"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aN2rJ3Z9GWio",
        "outputId": "69ac1c23-9e78-4dbf-9a60-e0aa555521b1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting matrix_mul_tiled_prof.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -O3 -arch=sm_75 matrix_mul_tiled_prof.cu -o matrix_mul_tiled_prof\n",
        "!nvprof ./matrix_mul_tiled_prof"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h2J-ZRxqGjof",
        "outputId": "e9631d79-7a8d-44c8-a934-2187496373c9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==736== NVPROF is profiling process 736, command: ./matrix_mul_tiled_prof\n",
            "Naive: 9.3891 ms  228.72 GFLOPS\n",
            "Tiled: 5.8105 ms  369.59 GFLOPS\n",
            "==736== Profiling application: ./matrix_mul_tiled_prof\n",
            "==736== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   55.14%  9.1868ms         1  9.1868ms  9.1868ms  9.1868ms  matmul_naive(float const *, float const *, float*, int, int, int)\n",
            "                   34.77%  5.7939ms         1  5.7939ms  5.7939ms  5.7939ms  matmul_tiled(float const *, float const *, float*, int, int, int)\n",
            "                   10.00%  1.6661ms         2  833.05us  795.37us  870.73us  [CUDA memcpy HtoD]\n",
            "                    0.09%  14.368us         1  14.368us  14.368us  14.368us  [CUDA memset]\n",
            "      API calls:   79.84%  73.721ms         3  24.574ms  71.749us  73.573ms  cudaMalloc\n",
            "                   16.65%  15.376ms         2  7.6879ms  5.8019ms  9.5739ms  cudaEventSynchronize\n",
            "                    2.22%  2.0527ms         2  1.0264ms  983.93us  1.0688ms  cudaMemcpy\n",
            "                    0.69%  633.99us         3  211.33us  178.58us  229.39us  cudaFree\n",
            "                    0.30%  280.36us         2  140.18us  20.891us  259.47us  cudaLaunchKernel\n",
            "                    0.18%  169.43us       114  1.4860us     125ns  69.055us  cuDeviceGetAttribute\n",
            "                    0.04%  34.070us         1  34.070us  34.070us  34.070us  cudaMemset\n",
            "                    0.02%  22.847us         4  5.7110us  3.5610us  6.8260us  cudaEventRecord\n",
            "                    0.02%  14.726us         1  14.726us  14.726us  14.726us  cuDeviceGetName\n",
            "                    0.02%  14.319us         2  7.1590us     729ns  13.590us  cudaEventCreate\n",
            "                    0.01%  10.550us         2  5.2750us  4.5620us  5.9880us  cudaEventElapsedTime\n",
            "                    0.01%  6.6990us         1  6.6990us  6.6990us  6.6990us  cuDeviceGetPCIBusId\n",
            "                    0.00%  2.4120us         3     804ns     143ns  1.8350us  cuDeviceGetCount\n",
            "                    0.00%  1.0200us         2     510ns     277ns     743ns  cuDeviceGet\n",
            "                    0.00%     801ns         1     801ns     801ns     801ns  cuDeviceTotalMem\n",
            "                    0.00%     427ns         1     427ns     427ns     427ns  cuModuleGetLoadingMode\n",
            "                    0.00%     243ns         1     243ns     243ns     243ns  cuDeviceGetUuid\n"
          ]
        }
      ]
    }
  ]
}