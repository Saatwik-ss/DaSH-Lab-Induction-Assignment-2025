{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCfB3P9qhzoN",
        "outputId": "496aa582-2aea-464a-e437-8ea119a1454e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Nov 11 18:08:04 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   62C    P8             11W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3N4khlOOhHX5",
        "outputId": "19318ab8-7320-4b06-fe05-7efa9424904c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2024 NVIDIA Corporation\n",
            "Built on Thu_Jun__6_02:18:23_PDT_2024\n",
            "Cuda compilation tools, release 12.5, V12.5.82\n",
            "Build cuda_12.5.r12.5/compiler.34385749_0\n"
          ]
        }
      ],
      "source": [
        "!nvcc --version\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile matrix_mul_naive.cu\n",
        "#include <iostream>\n",
        "#include <cuda_runtime.h>\n",
        "#define N 1024\n",
        "\n",
        "\n",
        "__global__ void matrixMulNaive(const float* A, const float* B, float* C, int n) {\n",
        "    int row=blockIdx.y*blockDim.y +threadIdx.y;\n",
        "    int col=blockIdx.x*blockDim.x +threadIdx.x;\n",
        "    if (row <n && col<n) {\n",
        "        float val=0.0f;\n",
        "        for (int k=0; k< n; ++k)\n",
        "            val += A[row*n + k]*B[k * n + col];\n",
        "        C[row*n + col] = val;\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "int main() {\n",
        "    int size = N * N * sizeof(float);\n",
        "    float *h_A = (float*)malloc(size);\n",
        "    float *h_B = (float*)malloc(size);\n",
        "    float *h_C = (float*)malloc(size);\n",
        "    for (int i = 0; i < N * N; i++) {\n",
        "        h_A[i] = static_cast<float>(rand()) / RAND_MAX;\n",
        "        h_B[i] = static_cast<float>(rand()) / RAND_MAX;\n",
        "    }\n",
        "\n",
        "    float *d_A, *d_B, *d_C;\n",
        "    cudaMalloc(&d_A, size);\n",
        "    cudaMalloc(&d_B, size);\n",
        "    cudaMalloc(&d_C, size);\n",
        "    cudaMemcpy(d_A, h_A, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_B, h_B, size, cudaMemcpyHostToDevice);\n",
        "    dim3 threads(16, 16);\n",
        "    dim3 blocks((N + threads.x - 1) / threads.x, (N + threads.y - 1) / threads.y);\n",
        "\n",
        "    cudaEvent_t start, stop;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "\n",
        "    // run kernel\n",
        "    cudaEventRecord(start);\n",
        "    matrixMulNaive<<<blocks, threads>>>(d_A, d_B, d_C, N);\n",
        "    cudaEventRecord(stop);\n",
        "    cudaEventSynchronize(stop);\n",
        "\n",
        "    float ms = 0.0f;\n",
        "    cudaEventElapsedTime(&ms, start, stop);\n",
        "    cudaMemcpy(h_C, d_C, size, cudaMemcpyDeviceToHost);\n",
        "    double flops = 2.0 * N * N * N;\n",
        "    double gflops = flops / (ms * 1e6);\n",
        "    std::cout << \"Native CUDA Matrix Multiplication:\\n\";\n",
        "    std::cout << ms << \" ms,  Performance: \" << gflops << \" GFLOPS\\n\";\n",
        "\n",
        "    cudaFree(d_A);\n",
        "    cudaFree(d_B);\n",
        "    cudaFree(d_C);\n",
        "    free(h_A);\n",
        "    free(h_B);\n",
        "    free(h_C);\n",
        "    return 0;\n",
        "}\n",
        "\n",
        "###### COMPILE ###########\n",
        "//!nvcc -O3 -arch=sm_75 matrix_mul_naive.cu -o matrix_mul_naive\n",
        "//!./matrix_mul_naive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OD9TkqHbh8o-",
        "outputId": "f8d36d05-3ac1-4e78-e8e0-049ad165ee6f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing matrix_mul_naive.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -O3 -arch=sm_75 matrix_mul_naive.cu -o matrix_mul_naive\n",
        "!./matrix_mul_naive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hyXok6RX99I9",
        "outputId": "ac095b64-21b9-4044-dfa3-362ce782b3ea"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[01m\u001b[0m\u001b[01mmatrix_mul_naive.cu(65)\u001b[0m: \u001b[01;31merror\u001b[0m: unrecognized preprocessing directive\n",
            "  ###### COMPILE ###########\n",
            "   ^\n",
            "\n",
            "1 error detected in the compilation of \"matrix_mul_naive.cu\".\n",
            "/bin/bash: line 1: ./matrix_mul_naive: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile matrix_mul_tiled_prof.cu\n",
        "#include <stdio.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "#define TILE 16\n",
        "\n",
        "__global__ void matmul_naive(const float *A,const float *B,float *C,int M,int N,int K){\n",
        " int row=blockIdx.y*blockDim.y+threadIdx.y;\n",
        " int col=blockIdx.x*blockDim.x+threadIdx.x;\n",
        " if(row<M && col<K){\n",
        "   float val=0;\n",
        "   for(int i=0;i<N;i++)\n",
        "     val+=A[row*N+i]*B[i*K+col];\n",
        "   C[row*K+col]=val;\n",
        " }\n",
        "}\n",
        "\n",
        "__global__ void matmul_tiled(const float *A,const float *B,float *C,int M,int N,int K){\n",
        " __shared__ float As[TILE][TILE];\n",
        " __shared__ float Bs[TILE][TILE];\n",
        " int row=blockIdx.y*TILE+threadIdx.y;\n",
        " int col=blockIdx.x*TILE+threadIdx.x;\n",
        " float val=0.0f;\n",
        " for(int t=0;t<(N+TILE-1)/TILE;t++){\n",
        "   if(row<M && t*TILE+threadIdx.x<N)\n",
        "     As[threadIdx.y][threadIdx.x]=A[row*N+t*TILE+threadIdx.x];\n",
        "   else As[threadIdx.y][threadIdx.x]=0.0f;\n",
        "\n",
        "   if(col<K && t*TILE+threadIdx.y<N)\n",
        "     Bs[threadIdx.y][threadIdx.x]=B[(t*TILE+threadIdx.y)*K+col];\n",
        "   else Bs[threadIdx.y][threadIdx.x]=0.0f;\n",
        "   __syncthreads();\n",
        "\n",
        "   for(int i=0;i<TILE;i++)\n",
        "     val+=As[threadIdx.y][i]*Bs[i][threadIdx.x];\n",
        "   __syncthreads();\n",
        " }\n",
        " if(row<M && col<K) C[row*K+col]=val;\n",
        "}\n",
        "\n",
        "void fill(float *a,int m,int n){\n",
        "  for(int i=0;i<m*n;i++) a[i]=(float)(rand()%10);\n",
        "}\n",
        "\n",
        "int main(){\n",
        " int M=1024,N=1024,K=1024;\n",
        " size_t sA=M*N*sizeof(float), sB=N*K*sizeof(float), sC=M*K*sizeof(float);\n",
        " float *hA=(float*)malloc(sA);\n",
        " float *hB=(float*)malloc(sB);\n",
        " float *hC=(float*)malloc(sC);\n",
        " fill(hA,M,N); fill(hB,N,K);\n",
        " float *dA,*dB,*dC;\n",
        " cudaMalloc(&dA,sA); cudaMalloc(&dB,sB); cudaMalloc(&dC,sC);\n",
        " cudaMemcpy(dA,hA,sA,cudaMemcpyHostToDevice);\n",
        " cudaMemcpy(dB,hB,sB,cudaMemcpyHostToDevice);\n",
        " dim3 block(TILE,TILE);\n",
        " dim3 grid((K+TILE-1)/TILE,(M+TILE-1)/TILE);\n",
        "\n",
        " cudaEvent_t start,stop;\n",
        " cudaEventCreate(&start); cudaEventCreate(&stop);\n",
        "\n",
        " cudaEventRecord(start);\n",
        " matmul_naive<<<grid,block>>>(dA,dB,dC,M,N,K);\n",
        " cudaEventRecord(stop);\n",
        " cudaEventSynchronize(stop);\n",
        " float ms1;\n",
        " cudaEventElapsedTime(&ms1,start,stop);\n",
        " double gflops1=2.0*M*N*K/(ms1/1000.0)/1e9;\n",
        " printf(\"Naive: %.4f ms  %.2f GFLOPS\\n\",ms1,gflops1);\n",
        "\n",
        " cudaMemset(dC,0,sC);\n",
        " cudaEventRecord(start);\n",
        " matmul_tiled<<<grid,block>>>(dA,dB,dC,M,N,K);\n",
        " cudaEventRecord(stop);\n",
        " cudaEventSynchronize(stop);\n",
        " float ms2;\n",
        " cudaEventElapsedTime(&ms2,start,stop);\n",
        " double gflops2=2.0*M*N*K/(ms2/1000.0)/1e9;\n",
        " printf(\"Tiled: %.4f ms  %.2f GFLOPS\\n\",ms2,gflops2);\n",
        "\n",
        " cudaFree(dA); cudaFree(dB); cudaFree(dC);\n",
        " free(hA); free(hB); free(hC);\n",
        " return 0;\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "//!nvcc -O3 -arch=sm_75 matrix_mul_tiled_prof.cu -o matrix_mul_tiled_prof\n",
        "//!nvprof ./matrix_mul_tiled_prof"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aN2rJ3Z9GWio",
        "outputId": "5098b013-0e70-483d-af31-bbc8931b688e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing matrix_mul_tiled_prof.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -O3 -arch=sm_75 matrix_mul_tiled_prof.cu -o matrix_mul_tiled_prof\n",
        "!nvprof ./matrix_mul_tiled_prof"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h2J-ZRxqGjof",
        "outputId": "85a88a34-8891-4d89-ffe4-843d23bae5c9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==674== NVPROF is profiling process 674, command: ./matrix_mul_tiled_prof\n",
            "Naive: 9.3643 ms  229.33 GFLOPS\n",
            "Tiled: 5.8026 ms  370.09 GFLOPS\n",
            "==674== Profiling application: ./matrix_mul_tiled_prof\n",
            "==674== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   55.51%  9.1975ms         1  9.1975ms  9.1975ms  9.1975ms  matmul_naive(float const *, float const *, float*, int, int, int)\n",
            "                   34.98%  5.7964ms         1  5.7964ms  5.7964ms  5.7964ms  matmul_tiled(float const *, float const *, float*, int, int, int)\n",
            "                    9.42%  1.5607ms         2  780.33us  756.14us  804.52us  [CUDA memcpy HtoD]\n",
            "                    0.09%  14.399us         1  14.399us  14.399us  14.399us  [CUDA memset]\n",
            "      API calls:   84.76%  106.30ms         3  35.433ms  66.524us  106.16ms  cudaMalloc\n",
            "                   11.96%  15.003ms         2  7.5015ms  5.8008ms  9.2022ms  cudaEventSynchronize\n",
            "                    1.88%  2.3518ms         2  1.1759ms  971.42us  1.3804ms  cudaMemcpy\n",
            "                    0.61%  764.44us         1  764.44us  764.44us  764.44us  cuDeviceGetPCIBusId\n",
            "                    0.42%  523.40us         3  174.47us  113.36us  207.76us  cudaFree\n",
            "                    0.14%  176.33us         2  88.166us  13.497us  162.84us  cudaLaunchKernel\n",
            "                    0.12%  149.96us       114  1.3150us     106ns  58.468us  cuDeviceGetAttribute\n",
            "                    0.07%  84.706us         2  42.353us     639ns  84.067us  cudaEventCreate\n",
            "                    0.02%  22.539us         1  22.539us  22.539us  22.539us  cudaMemset\n",
            "                    0.01%  15.157us         4  3.7890us  2.1690us  5.4310us  cudaEventRecord\n",
            "                    0.01%  12.757us         1  12.757us  12.757us  12.757us  cuDeviceGetName\n",
            "                    0.00%  5.0710us         2  2.5350us  1.7720us  3.2990us  cudaEventElapsedTime\n",
            "                    0.00%  2.5290us         2  1.2640us     185ns  2.3440us  cuDeviceGet\n",
            "                    0.00%  1.6610us         3     553ns     155ns  1.1900us  cuDeviceGetCount\n",
            "                    0.00%     461ns         1     461ns     461ns     461ns  cuDeviceTotalMem\n",
            "                    0.00%     387ns         1     387ns     387ns     387ns  cuModuleGetLoadingMode\n",
            "                    0.00%     290ns         1     290ns     290ns     290ns  cuDeviceGetUuid\n"
          ]
        }
      ]
    }
  ]
}